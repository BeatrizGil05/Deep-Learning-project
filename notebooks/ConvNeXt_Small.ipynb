{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ccfe4782",
      "metadata": {},
      "source": [
        "# Rare Species Classification using ConvNeXt-Small\n",
        "\n",
        "This notebook presents the training pipeline for a rare species image classification task.\n",
        "The goal is to classify images into biological families using a deep convolutional neural\n",
        "network based on ConvNeXt-Small, pretrained on ImageNet."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c13dd55",
      "metadata": {},
      "source": [
        "## Imports and Reproducibility\n",
        "\n",
        "This section loads all required libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib), and deep learning (TensorFlow/Keras). We also set a global random seed to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e193775a",
      "metadata": {
        "id": "e193775a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 23:42:15.230633: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ConvNeXtSmall\n",
        "from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e146c4fc",
      "metadata": {},
      "source": [
        "## Hardware Configuration\n",
        "\n",
        "GPU availability is checked and memory growth is enabled to avoid out-of-memory errors\n",
        "during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99afab38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99afab38",
        "outputId": "0a93d968-fe05-4987-947d-a665a4e5b2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GPU CHECK\n",
            "================================================================================\n",
            "✓ 1 GPU(s) available\n",
            "  - PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GPU CHECK\")\n",
        "print(\"=\"*80)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✓ {len(gpus)} GPU(s) available\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"  - {gpu}\")\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    print(\"⚠ No GPU detected - training will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a7bb7e",
      "metadata": {},
      "source": [
        "## Dataset Loading and Cleaning\n",
        "\n",
        "The dataset metadata is loaded from a CSV file and the full file paths are construtcted. We perform a validity check to remove any entries where the image file does not exist or the label is missing. Finally, we handle duplicates and stratify the data into Train (80%), Validation (10%), and Test (10%) sets to preserve class distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30a5340",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b30a5340",
        "outputId": "b33c0cc2-b842-413b-ae02-958418e8d7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DATA PREPROCESSING\n",
            "================================================================================\n",
            "Number of missing files: 123\n",
            "Cleaned data: 11860 images\n",
            "Number of categories (families): 202\n",
            "Train: 9488\n",
            "Val: 1186\n",
            "Test: 1186\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df = pd.read_csv('../metadata.csv')\n",
        "data_root_path = \"/home/user/datasets/rare_species/\"\n",
        "df['full_path'] = df['file_path'].apply(lambda x: os.path.join(data_root_path, x))\n",
        "\n",
        "df = df.dropna(subset=['file_path', 'family']).reset_index(drop=True)\n",
        "\n",
        "df['exists'] = df['full_path'].apply(os.path.exists)\n",
        "print(f\"Number of missing files: {len(df[df['exists'] == False])}\")\n",
        "df = df[df['exists'] == True].reset_index(drop=True)\n",
        "\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "df = df.drop_duplicates(subset='full_path').reset_index(drop=True)\n",
        "\n",
        "print(f\"Cleaned data: {len(df)} images\")\n",
        "print(f\"Number of categories (families): {df['family'].nunique()}\")\n",
        "df['family'] = df['family'].astype(str)\n",
        "\n",
        "# Stratified split: 80% train, 10% val, 10% test\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.10,\n",
        "    stratify=df[\"family\"],\n",
        "    random_state=SEED\n",
        ")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.1111,  # 0.1111 * 0.9 = 0.10\n",
        "    stratify=train_val_df[\"family\"],\n",
        "    random_state=SEED\n",
        ")\n",
        "print(f\"Train: {len(train_df)}\")\n",
        "print(f\"Val: {len(val_df)}\")\n",
        "print(f\"Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98f4346",
      "metadata": {},
      "source": [
        "## Image Preprocessing and Data Augmentation\n",
        "\n",
        "Images are resized to 224×224 pixels and preprocessed using the official ConvNeXt\n",
        "preprocessing function. Data augmentation is applied only to the training set to\n",
        "improve generalization.\n",
        "\n",
        "The validation and test sets are only preprocessed without augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca7f0d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ca7f0d0",
        "outputId": "2500fe7d-f8f0-4122-eb9e-14d04f3d821a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "BUILDING DATA GENERATORS\n",
            "================================================================================\n",
            "Found 9488 validated image filenames belonging to 202 classes.\n",
            "Found 1186 validated image filenames belonging to 202 classes.\n",
            "Found 1186 validated image filenames belonging to 202 classes.\n",
            "Train batches: 593\n",
            "Val batches: 75\n",
            "Test batches: 75\n",
            "Number of classes: 202\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BUILDING DATA GENERATORS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=convnext_preprocess,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.15,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=convnext_preprocess\n",
        ")\n",
        "\n",
        "train_ds = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_ds)}\")\n",
        "print(f\"Val batches: {len(val_ds)}\")\n",
        "print(f\"Test batches: {len(test_ds)}\")\n",
        "print(f\"Number of classes: {len(train_ds.class_indices)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6540d5bf",
      "metadata": {},
      "source": [
        "## Class Imbalance Handling\n",
        "\n",
        "The dataset is highly imbalanced across species families. To mitigate this issue,\n",
        "class weights are computed from the training labels and passed to the loss function\n",
        "during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e1679664",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1679664",
        "outputId": "1e591e15-c1f6-4142-e51e-b78970f416e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPUTING CLASS WEIGHTS\n",
            "================================================================================\n",
            "Class weights computed for 202 classes\n",
            "Weight range: 0.197 to 2.135\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPUTING CLASS WEIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "labels = train_ds.classes\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "class_weights = dict(enumerate(weights))\n",
        "print(f\"Class weights computed for {len(class_weights)} classes\")\n",
        "print(f\"Weight range: {min(weights):.3f} to {max(weights):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5cb08e",
      "metadata": {},
      "source": [
        "## Model Architecture: ConvNeXt-Small\n",
        "\n",
        "ConvNeXt-Small pretrained on ImageNet is used as the backbone feature extractor.\n",
        "The original classification head is removed and replaced with a custom head consisting of:\n",
        "\n",
        "- Global Average Pooling\n",
        "- Fully connected layer with ReLU activation\n",
        "- Batch Normalization\n",
        "- Dropout for regularization\n",
        "- Final Softmax layer for family classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5f4cce94",
      "metadata": {
        "id": "5f4cce94"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes, trainable_backbone=False):\n",
        "    \"\"\"\n",
        "    Create ConvNeXt-Small model with custom head\n",
        "\n",
        "    Args:\n",
        "        num_classes: Number of output classes\n",
        "        trainable_backbone: Whether to make backbone trainable\n",
        "    \"\"\"\n",
        "    print(f\"\\nBuilding model (backbone trainable: {trainable_backbone})\")\n",
        "\n",
        "    # Load pretrained ConvNeXt-Small\n",
        "    base_model = ConvNeXtSmall(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "        pooling=None\n",
        "    )\n",
        "\n",
        "    base_model.trainable = trainable_backbone\n",
        "\n",
        "    # Build custom head\n",
        "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    print(f\"Total parameters: {model.count_params():,}\")\n",
        "    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def unfreeze_top_layers(model, percentage=0.3):\n",
        "    \"\"\"\n",
        "    Unfreeze top percentage of backbone layers\n",
        "\n",
        "    Args:\n",
        "        model: Keras model\n",
        "        percentage: Percentage of layers to unfreeze (from the end)\n",
        "    \"\"\"\n",
        "    base_model = model.layers[1]  # The ConvNeXt backbone\n",
        "    total_layers = len(base_model.layers)\n",
        "    unfreeze_from = int(total_layers * (1 - percentage))\n",
        "\n",
        "    print(f\"\\nUnfreezing top {percentage*100}% of backbone layers\")\n",
        "    print(f\"Total backbone layers: {total_layers}\")\n",
        "    print(f\"Unfreezing from layer {unfreeze_from} onwards\")\n",
        "\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:unfreeze_from]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "    print(f\"Trainable parameters after unfreezing: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dee0b78f",
      "metadata": {
        "id": "dee0b78f"
      },
      "outputs": [],
      "source": [
        "def get_callbacks(stage_name, patience=4):\n",
        "    \"\"\"Get training callbacks for a specific stage\"\"\"\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    callbacks = [\n",
        "        # Save best model\n",
        "        ModelCheckpoint(\n",
        "            filepath=f'model_{stage_name}_best.keras',\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "\n",
        "        # Reduce learning rate when stuck\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1,\n",
        "            mode='max'\n",
        "        ),\n",
        "\n",
        "        # Early stopping\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=patience,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1,\n",
        "            mode='max'\n",
        "        ),\n",
        "\n",
        "        # TensorBoard logging\n",
        "        TensorBoard(\n",
        "            log_dir=f'logs/{stage_name}_{timestamp}',\n",
        "            histogram_freq=0\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "HyOK9bzXYK03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "HyOK9bzXYK03",
        "outputId": "22fa2372-7bf1-42fc-af1e-695fdce62029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL ARCHITECTURE\n",
            "================================================================================\n",
            "\n",
            "Building model (backbone trainable: False)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1765410159.051575   17867 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3537 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 49,954,090\n",
            "Trainable parameters: 498,378\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ convnext_small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">49,454,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ convnext_small (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │    \u001b[38;5;34m49,454,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m103,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,954,090</span> (190.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,954,090\u001b[0m (190.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">498,378</span> (1.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m498,378\u001b[0m (1.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,455,712</span> (188.66 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m49,455,712\u001b[0m (188.66 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "    # Build model\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MODEL ARCHITECTURE\")\n",
        "    print(\"=\"*80)\n",
        "    num_classes = len(train_ds.class_indices)\n",
        "    model = build_model(num_classes=num_classes, trainable_backbone=False)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad747a07",
      "metadata": {},
      "source": [
        "## Training Strategy\n",
        "\n",
        "Training is performed in three stages:\n",
        "\n",
        "1. Training only the custom classification head with the backbone frozen\n",
        "2. Fine-tuning the top 30% of the ConvNeXt backbone\n",
        "3. Full fine-tuning of the backbone with Batch Normalization layers frozen\n",
        "\n",
        "This gradual unfreezing strategy stabilizes training and improves performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e46ea9",
      "metadata": {},
      "source": [
        "## Stage 1: Training with Frozen Backbone\n",
        "\n",
        "In the first stage, the ConvNeXt-Small backbone is kept frozen and only the newly\n",
        "added classification head is trained. This allows the model to adapt high-level\n",
        "features to the new task without destroying pretrained representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a20f6c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20f6c2f",
        "outputId": "36cbb3ee-3a7c-4e57-f247-804eebb2d0fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STAGE 1: Training with FROZEN backbone\n",
            "================================================================================\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 14:42:27.548021: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f0d5c0021c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-12-10 14:42:27.548084: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
            "2025-12-10 14:42:28.778701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-10 14:42:33.700810: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91700\n",
            "2025-12-10 14:42:39.333571: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:41.442056: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:42.062074: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:42.082041: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:42.159228: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:42.218212: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:43.233767: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n",
            "2025-12-10 14:42:46.844459: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng20{k2=1,k4=3,k5=1,k6=0,k7=0,k19=0} for conv (f32[16,96,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,224,224]{3,2,1,0}, f32[96,3,4,4]{3,2,1,0}, f32[96]{0}), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-10 14:42:47.496363: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.65145943s\n",
            "Trying algorithm eng20{k2=1,k4=3,k5=1,k6=0,k7=0,k19=0} for conv (f32[16,96,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,224,224]{3,2,1,0}, f32[96,3,4,4]{3,2,1,0}, f32[96]{0}), window={size=4x4 stride=4x4}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-10 14:42:50.584194: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng3{k11=0} for conv (f32[16,192,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,192,28,28]{3,2,1,0}, f32[192,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=192, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-10 14:42:50.663882: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.079801896s\n",
            "Trying algorithm eng3{k11=0} for conv (f32[16,192,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,192,28,28]{3,2,1,0}, f32[192,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=192, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-10 14:42:51.880726: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 14:42:52.106931: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "I0000 00:00:1765377786.667972   67875 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.0844 - loss: 5.1209 - top5_acc: 0.1848"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 14:51:29.247457: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:30.442291: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:30.622576: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:30.728646: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:31.113894: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:31.192352: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:31.460153: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:31.877514: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:32.056610: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:32.057002: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:34.021596: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:34.161406: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:34.279002: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 10956 bytes spill stores, 10116 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:34.384264: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 1616 bytes spill stores, 1212 bytes spill loads\n",
            "\n",
            "2025-12-10 14:51:34.417579: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from None to 0.41906, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 885ms/step - accuracy: 0.1778 - loss: 4.3371 - top5_acc: 0.3496 - val_accuracy: 0.4191 - val_loss: 2.5530 - val_top5_acc: 0.7243 - learning_rate: 3.0000e-04\n",
            "Epoch 2/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.3910 - loss: 2.6875 - top5_acc: 0.6808\n",
            "Epoch 2: val_accuracy improved from 0.41906 to 0.49916, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 865ms/step - accuracy: 0.4186 - loss: 2.4892 - top5_acc: 0.7112 - val_accuracy: 0.4992 - val_loss: 1.9513 - val_top5_acc: 0.8103 - learning_rate: 3.0000e-04\n",
            "Epoch 3/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step - accuracy: 0.4983 - loss: 1.9144 - top5_acc: 0.7924\n",
            "Epoch 3: val_accuracy improved from 0.49916 to 0.55312, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 924ms/step - accuracy: 0.5080 - loss: 1.8596 - top5_acc: 0.8008 - val_accuracy: 0.5531 - val_loss: 1.7192 - val_top5_acc: 0.8373 - learning_rate: 3.0000e-04\n",
            "Epoch 4/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821ms/step - accuracy: 0.5499 - loss: 1.5965 - top5_acc: 0.8248\n",
            "Epoch 4: val_accuracy improved from 0.55312 to 0.57504, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 916ms/step - accuracy: 0.5504 - loss: 1.5892 - top5_acc: 0.8289 - val_accuracy: 0.5750 - val_loss: 1.5992 - val_top5_acc: 0.8533 - learning_rate: 3.0000e-04\n",
            "Epoch 5/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679ms/step - accuracy: 0.5878 - loss: 1.4403 - top5_acc: 0.8578\n",
            "Epoch 5: val_accuracy did not improve from 0.57504\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 746ms/step - accuracy: 0.5870 - loss: 1.3994 - top5_acc: 0.8583 - val_accuracy: 0.5700 - val_loss: 1.5712 - val_top5_acc: 0.8642 - learning_rate: 3.0000e-04\n",
            "Epoch 6/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - accuracy: 0.6074 - loss: 1.2524 - top5_acc: 0.8701\n",
            "Epoch 6: val_accuracy improved from 0.57504 to 0.59612, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 755ms/step - accuracy: 0.6139 - loss: 1.2496 - top5_acc: 0.8753 - val_accuracy: 0.5961 - val_loss: 1.4802 - val_top5_acc: 0.8693 - learning_rate: 3.0000e-04\n",
            "Epoch 7/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - accuracy: 0.6409 - loss: 1.1172 - top5_acc: 0.8895\n",
            "Epoch 7: val_accuracy improved from 0.59612 to 0.60287, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 920ms/step - accuracy: 0.6344 - loss: 1.1424 - top5_acc: 0.8906 - val_accuracy: 0.6029 - val_loss: 1.4751 - val_top5_acc: 0.8744 - learning_rate: 3.0000e-04\n",
            "Epoch 8/8\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662ms/step - accuracy: 0.6540 - loss: 1.0165 - top5_acc: 0.9090\n",
            "Epoch 8: val_accuracy improved from 0.60287 to 0.61804, saving model to model_stage1_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 731ms/step - accuracy: 0.6576 - loss: 1.0296 - top5_acc: 0.9059 - val_accuracy: 0.6180 - val_loss: 1.4250 - val_top5_acc: 0.8811 - learning_rate: 3.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\n",
            "Stage 1 COMPLETE! Model saved.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STAGE 1: Training with FROZEN backbone\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=3e-4,\n",
        "        weight_decay=1e-4\n",
        "    ),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')]\n",
        ")\n",
        "\n",
        "# Train\n",
        "history1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=8,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=get_callbacks('stage1', patience=4),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save\n",
        "model.save('model_after_stage1.keras')\n",
        "print(f\"\\nStage 1 COMPLETE! Model saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8bdeca6",
      "metadata": {},
      "source": [
        "## Stage 2: Partial Fine-Tuning (Top 30%)\n",
        "\n",
        "In the second stage, the top 30% of ConvNeXt-Small layers are unfrozen.\n",
        "A lower learning rate is used to refine pretrained features while\n",
        "reducing the risk of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XtWPVPkYUz-P",
      "metadata": {
        "id": "XtWPVPkYUz-P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STAGE 2: Training with PARTIAL backbone unfreezing (top 30%)\n",
            "================================================================================\n",
            "\n",
            "Unfreezing top 30.0% of backbone layers\n",
            "Total backbone layers: 259\n",
            "Unfreezing from layer 181 onwards\n",
            "Trainable parameters after unfreezing: 25,566,666\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 16:06:40.922846: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f9414018830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-12-10 16:06:40.923192: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
            "2025-12-10 16:06:41.859234: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-10 16:06:46.699871: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91700\n",
            "2025-12-10 16:06:52.485092: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:53.231441: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:53.722830: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:54.130280: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:54.211432: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:54.283629: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:56.607611: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n",
            "2025-12-10 16:06:59.976681: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:00.241175: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:00.332944: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:00.509223: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:00.731962: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:01.204652: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:01.514204: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:01.806452: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:01.826504: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng3{k11=0} for conv (f32[16,768,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,768,7,7]{3,2,1,0}, f32[768,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=768, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-10 16:07:02.052337: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:02.340228: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:02.679363: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:02.920344: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-10 16:07:02.932676: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.106242158s\n",
            "Trying algorithm eng3{k11=0} for conv (f32[16,768,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,768,7,7]{3,2,1,0}, f32[768,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=768, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "I0000 00:00:1765382833.748303   80572 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782ms/step - accuracy: 0.6899 - loss: 0.9215 - top5_acc: 0.9245"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 16:16:02.236135: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:02.498233: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:03.692467: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:04.723217: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:05.260482: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:05.516152: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:06.135598: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:06.534070: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:06.880130: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:06.964133: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:07.522165: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 10956 bytes spill stores, 10116 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:07.706880: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:07.727697: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:07.940975: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n",
            "2025-12-10 16:16:08.003896: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 1616 bytes spill stores, 1212 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from None to 0.62226, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 930ms/step - accuracy: 0.6812 - loss: 0.9455 - top5_acc: 0.9202 - val_accuracy: 0.6223 - val_loss: 1.3897 - val_top5_acc: 0.8853 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - accuracy: 0.6956 - loss: 0.8747 - top5_acc: 0.9248\n",
            "Epoch 2: val_accuracy improved from 0.62226 to 0.62901, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 761ms/step - accuracy: 0.6897 - loss: 0.8754 - top5_acc: 0.9246 - val_accuracy: 0.6290 - val_loss: 1.3764 - val_top5_acc: 0.8879 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - accuracy: 0.6921 - loss: 0.8560 - top5_acc: 0.9237\n",
            "Epoch 3: val_accuracy did not improve from 0.62901\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 706ms/step - accuracy: 0.6935 - loss: 0.8553 - top5_acc: 0.9277 - val_accuracy: 0.6256 - val_loss: 1.3708 - val_top5_acc: 0.8862 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692ms/step - accuracy: 0.7013 - loss: 0.8415 - top5_acc: 0.9268\n",
            "Epoch 4: val_accuracy improved from 0.62901 to 0.63575, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 779ms/step - accuracy: 0.7068 - loss: 0.8391 - top5_acc: 0.9257 - val_accuracy: 0.6358 - val_loss: 1.3597 - val_top5_acc: 0.8879 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.7186 - loss: 0.7645 - top5_acc: 0.9391\n",
            "Epoch 5: val_accuracy did not improve from 0.63575\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 802ms/step - accuracy: 0.7141 - loss: 0.7814 - top5_acc: 0.9361 - val_accuracy: 0.6358 - val_loss: 1.3579 - val_top5_acc: 0.8929 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677ms/step - accuracy: 0.7224 - loss: 0.7584 - top5_acc: 0.9379\n",
            "Epoch 6: val_accuracy improved from 0.63575 to 0.64250, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 747ms/step - accuracy: 0.7176 - loss: 0.7683 - top5_acc: 0.9343 - val_accuracy: 0.6425 - val_loss: 1.3392 - val_top5_acc: 0.8929 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.7277 - loss: 0.7288 - top5_acc: 0.9379\n",
            "Epoch 7: val_accuracy did not improve from 0.64250\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 436ms/step - accuracy: 0.7199 - loss: 0.7520 - top5_acc: 0.9364 - val_accuracy: 0.6358 - val_loss: 1.3768 - val_top5_acc: 0.8904 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.7341 - loss: 0.7177 - top5_acc: 0.9364\n",
            "Epoch 8: val_accuracy improved from 0.64250 to 0.64924, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 712ms/step - accuracy: 0.7299 - loss: 0.7289 - top5_acc: 0.9376 - val_accuracy: 0.6492 - val_loss: 1.3301 - val_top5_acc: 0.8954 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754ms/step - accuracy: 0.7323 - loss: 0.7397 - top5_acc: 0.9436\n",
            "Epoch 9: val_accuracy improved from 0.64924 to 0.65261, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 835ms/step - accuracy: 0.7288 - loss: 0.7242 - top5_acc: 0.9436 - val_accuracy: 0.6526 - val_loss: 1.3246 - val_top5_acc: 0.8946 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644ms/step - accuracy: 0.7487 - loss: 0.6625 - top5_acc: 0.9417\n",
            "Epoch 10: val_accuracy did not improve from 0.65261\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 704ms/step - accuracy: 0.7397 - loss: 0.6856 - top5_acc: 0.9392 - val_accuracy: 0.6459 - val_loss: 1.3220 - val_top5_acc: 0.8904 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641ms/step - accuracy: 0.7449 - loss: 0.6799 - top5_acc: 0.9436\n",
            "Epoch 11: val_accuracy did not improve from 0.65261\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 702ms/step - accuracy: 0.7368 - loss: 0.6958 - top5_acc: 0.9433 - val_accuracy: 0.6383 - val_loss: 1.3139 - val_top5_acc: 0.8929 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634ms/step - accuracy: 0.7588 - loss: 0.6492 - top5_acc: 0.9447\n",
            "Epoch 12: val_accuracy did not improve from 0.65261\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 704ms/step - accuracy: 0.7512 - loss: 0.6732 - top5_acc: 0.9452 - val_accuracy: 0.6492 - val_loss: 1.2979 - val_top5_acc: 0.8980 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618ms/step - accuracy: 0.7374 - loss: 0.6764 - top5_acc: 0.9455\n",
            "Epoch 13: val_accuracy did not improve from 0.65261\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 688ms/step - accuracy: 0.7434 - loss: 0.6603 - top5_acc: 0.9483 - val_accuracy: 0.6509 - val_loss: 1.2930 - val_top5_acc: 0.8971 - learning_rate: 5.0000e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653ms/step - accuracy: 0.7675 - loss: 0.6350 - top5_acc: 0.9545\n",
            "Epoch 14: val_accuracy improved from 0.65261 to 0.65430, saving model to model_stage2_best.keras\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 719ms/step - accuracy: 0.7623 - loss: 0.6304 - top5_acc: 0.9490 - val_accuracy: 0.6543 - val_loss: 1.2929 - val_top5_acc: 0.8980 - learning_rate: 5.0000e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step - accuracy: 0.7572 - loss: 0.6266 - top5_acc: 0.9512\n",
            "Epoch 15: val_accuracy did not improve from 0.65430\n",
            "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 693ms/step - accuracy: 0.7541 - loss: 0.6331 - top5_acc: 0.9492 - val_accuracy: 0.6484 - val_loss: 1.2915 - val_top5_acc: 0.8980 - learning_rate: 5.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "\n",
            "Stage 2 COMPLETE! Model saved.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STAGE 2: Training with PARTIAL backbone unfreezing (top 30%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = tf.keras.models.load_model('model_after_stage1.keras') #balazs: switched it with next line\n",
        "\n",
        "# Unfreeze top layers\n",
        "unfreeze_top_layers(model, percentage=0.3)\n",
        "\n",
        "\n",
        "# Compile with lower learning rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=1e-4,# balazs: it was too low didnt learn. was 1e-5\n",
        "        weight_decay=1e-4\n",
        "    ),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')]\n",
        ")\n",
        "\n",
        "# Train\n",
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=get_callbacks('stage2', patience=5),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save\n",
        "model.save('model_after_stage2.keras')\n",
        "print(f\"\\nStage 2 COMPLETE! Model saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3720999",
      "metadata": {},
      "source": [
        "## Stage 3: Full Fine-Tuning\n",
        "\n",
        "In the final stage, all backbone layers are unfrozen except Batch Normalization layers,\n",
        "which remain frozen for training stability. Mixed-precision training and a smaller\n",
        "batch size are used to fit GPU memory constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KsXwRQdXU0Lh",
      "metadata": {
        "id": "KsXwRQdXU0Lh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STAGE 3: Training with FULL backbone unfreezing\n",
            "================================================================================\n",
            "Found 9488 validated image filenames belonging to 202 classes.\n",
            "Found 1186 validated image filenames belonging to 202 classes.\n",
            "Trainable parameters: 48,397,194\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 23:44:16.310624: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f20e0006e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-12-10 23:44:16.310723: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
            "2025-12-10 23:44:17.574275: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-10 23:44:31.175575: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91700\n",
            "2025-12-10 23:44:41.110240: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:41.616222: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:42.151255: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_78', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:42.694502: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:42.763021: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 1616 bytes spill stores, 1212 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:42.838952: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:43.077718: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 10956 bytes spill stores, 10116 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:43.179012: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:43.325775: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_216', 152 bytes spill stores, 152 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:43.419310: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:43.737772: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_217', 100 bytes spill stores, 100 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:44.678456: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:45.401819: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:45.634382: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:46.122675: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:46.992996: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:48.234397: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_132', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:48.320019: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_79', 1664 bytes spill stores, 1344 bytes spill loads\n",
            "\n",
            "2025-12-10 23:44:49.001499: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 11912 bytes spill stores, 10644 bytes spill loads\n",
            "\n",
            "I0000 00:00:1765410334.684216   18059 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8447 - loss: 0.4167 - top5_acc: 0.9690"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-10 23:53:25.628381: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:26.470727: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:26.546802: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:26.555769: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:26.765302: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:27.242867: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:27.625038: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:27.884118: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:27.914705: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:27.928751: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:28.055850: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:28.389107: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13', 1616 bytes spill stores, 1212 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:28.745486: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 10956 bytes spill stores, 10116 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:28.746716: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-10 23:53:28.834121: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from None to 0.74789, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 207ms/step - accuracy: 0.8491 - loss: 0.4029 - top5_acc: 0.9727 - val_accuracy: 0.7479 - val_loss: 1.0769 - val_top5_acc: 0.9216 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8617 - loss: 0.3690 - top5_acc: 0.9764\n",
            "Epoch 2: val_accuracy improved from 0.74789 to 0.74874, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 199ms/step - accuracy: 0.8553 - loss: 0.3765 - top5_acc: 0.9742 - val_accuracy: 0.7487 - val_loss: 1.0657 - val_top5_acc: 0.9250 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8653 - loss: 0.3561 - top5_acc: 0.9758\n",
            "Epoch 3: val_accuracy improved from 0.74874 to 0.75211, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 199ms/step - accuracy: 0.8641 - loss: 0.3507 - top5_acc: 0.9763 - val_accuracy: 0.7521 - val_loss: 1.0472 - val_top5_acc: 0.9258 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8687 - loss: 0.3288 - top5_acc: 0.9776\n",
            "Epoch 4: val_accuracy improved from 0.75211 to 0.76054, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 198ms/step - accuracy: 0.8744 - loss: 0.3227 - top5_acc: 0.9799 - val_accuracy: 0.7605 - val_loss: 1.0391 - val_top5_acc: 0.9258 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8809 - loss: 0.3002 - top5_acc: 0.9784\n",
            "Epoch 5: val_accuracy did not improve from 0.76054\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 194ms/step - accuracy: 0.8776 - loss: 0.3027 - top5_acc: 0.9796 - val_accuracy: 0.7555 - val_loss: 1.0494 - val_top5_acc: 0.9300 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8836 - loss: 0.2761 - top5_acc: 0.9826\n",
            "Epoch 6: val_accuracy improved from 0.76054 to 0.76476, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 198ms/step - accuracy: 0.8832 - loss: 0.2807 - top5_acc: 0.9820 - val_accuracy: 0.7648 - val_loss: 1.0324 - val_top5_acc: 0.9275 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8994 - loss: 0.2537 - top5_acc: 0.9875\n",
            "Epoch 7: val_accuracy improved from 0.76476 to 0.77066, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 197ms/step - accuracy: 0.8968 - loss: 0.2540 - top5_acc: 0.9852 - val_accuracy: 0.7707 - val_loss: 1.0150 - val_top5_acc: 0.9283 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8926 - loss: 0.2569 - top5_acc: 0.9873\n",
            "Epoch 8: val_accuracy improved from 0.77066 to 0.77403, saving model to model_stage3_best.keras\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 196ms/step - accuracy: 0.8988 - loss: 0.2467 - top5_acc: 0.9870 - val_accuracy: 0.7740 - val_loss: 1.0120 - val_top5_acc: 0.9275 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9070 - loss: 0.2209 - top5_acc: 0.9866\n",
            "Epoch 9: val_accuracy did not improve from 0.77403\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 193ms/step - accuracy: 0.9060 - loss: 0.2252 - top5_acc: 0.9860 - val_accuracy: 0.7740 - val_loss: 1.0114 - val_top5_acc: 0.9342 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9137 - loss: 0.2026 - top5_acc: 0.9882\n",
            "Epoch 10: val_accuracy did not improve from 0.77403\n",
            "\u001b[1m2372/2372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 195ms/step - accuracy: 0.9132 - loss: 0.2055 - top5_acc: 0.9876 - val_accuracy: 0.7732 - val_loss: 1.0032 - val_top5_acc: 0.9325 - learning_rate: 1.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\n",
            "Stage 3 COMPLETE! Model saved.\n"
          ]
        }
      ],
      "source": [
        "# Stage 3: Fine-tune all layers0\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STAGE 3: Training with FULL backbone unfreezing\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = tf.keras.models.load_model('model_after_stage2.keras')\n",
        "\n",
        "# --- Mixed precision ---\n",
        "from tensorflow.keras import mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# --- Recreate generators with smaller batch size if needed ---\n",
        "NEW_BATCH_SIZE = 4\n",
        "\n",
        "train_ds_stage3 = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=NEW_BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds_stage3 = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=NEW_BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\"\"\"\n",
        "# Unfreeze all layers\n",
        "base_model = model.layers[1]\n",
        "base_model.trainable = True\"\"\"\n",
        "\n",
        "# Unfreeze all layers but freeze BatchNorm layers\n",
        "base_model = model.layers[1]\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n",
        "\n",
        "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Compile with even lower learning rate\n",
        "opt = tf.keras.optimizers.AdamW(\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=1e-5\n",
        ")\n",
        "opt = mixed_precision.LossScaleOptimizer(opt)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')]\n",
        ")\n",
        "\n",
        "# Train\n",
        "history3 = model.fit(\n",
        "    train_ds_stage3,\n",
        "    validation_data=val_ds_stage3,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=get_callbacks('stage3', patience=5),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save\n",
        "model.save('model_after_stage3.keras')\n",
        "print(f\"\\nStage 3 COMPLETE! Model saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1f2bdc",
      "metadata": {},
      "source": [
        "## Final Evaluation\n",
        "\n",
        "The final model is evaluated on the independent test set using accuracy\n",
        "and macro-averaged precision, recall, and F1-score.\n",
        "Macro metrics are reported to account for class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7077b6a3",
      "metadata": {
        "id": "7077b6a3"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_ds):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL EVALUATION ON TEST SET\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results = model.evaluate(test_ds, verbose=1)\n",
        "    test_ds.reset()\n",
        "    predictions = model.predict(test_ds, verbose=1)\n",
        "\n",
        "    # Convert probabilities to class labels\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    y_true = test_ds.classes\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    prec_macro = precision_score(y_true, y_pred, average='macro')\n",
        "    rec_macro = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(\"\\nFinal test metrics:\")\n",
        "    print(f\"Accuracy:          {acc:.2%}\")\n",
        "    print(f\"Macro F1-Score:    {f1_macro:.2%}\")\n",
        "    print(f\"Macro Precision:   {prec_macro:.2%}\")\n",
        "    print(f\"Macro Recall:      {rec_macro:.2%}\")\n",
        "\n",
        "    return results, {'accuracy': acc, 'f1': f1_macro, 'precision': prec_macro, 'recall': rec_macro}\n",
        "\n",
        "def plot_training_history(histories, stage_names):\n",
        "    \"\"\"Plot training curves for all stages with phase separation lines\"\"\"\n",
        "\n",
        "    # Combine all histories\n",
        "    acc = []\n",
        "    val_acc = []\n",
        "    loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for history in histories:\n",
        "        if history is not None:\n",
        "            acc.extend(history.history['accuracy'])\n",
        "            val_acc.extend(history.history['val_accuracy'])\n",
        "            loss.extend(history.history['loss'])\n",
        "            val_loss.extend(history.history['val_loss'])\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "\n",
        "    # Add vertical lines to show where each phase started\n",
        "    phase1_end = len(histories[0].history['accuracy'])\n",
        "    phase2_end = phase1_end + len(histories[1].history['accuracy'])\n",
        "\n",
        "    plt.axvline(x=phase1_end, color='black', linestyle='--', label='Start Stage 2', linewidth=2)\n",
        "    plt.axvline(x=phase2_end, color='red', linestyle='--', label='Start Stage 3', linewidth=2)\n",
        "\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "\n",
        "    plt.axvline(x=phase1_end, color='black', linestyle='--', label='Start Stage 2', linewidth=2)\n",
        "    plt.axvline(x=phase2_end, color='red', linestyle='--', label='Start Stage 3', linewidth=2)\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=300)\n",
        "    print(f\"\\n Training history plot saved to training_history.png\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "59d94c40",
      "metadata": {
        "id": "59d94c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL EVALUATION ON TEST SET\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-11 01:04:58.071142: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:58.302014: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:59.070452: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:59.259784: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:59.277006: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-11 01:05:00.430774: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n",
            "2025-12-11 01:05:00.464510: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-11 01:05:04.713891: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:05.784804: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:06.460915: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:06.790639: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.064524: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.110137: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng3{k11=0} for conv (f32[16,768,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,768,7,7]{3,2,1,0}, f32[768,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=768, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-11 01:05:07.344499: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.642443: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.962583: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:08.295056: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:08.617001: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:08.941385: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:09.246463: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:09.254836: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.144878511s\n",
            "Trying algorithm eng3{k11=0} for conv (f32[16,768,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,768,7,7]{3,2,1,0}, f32[768,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=768, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m21/75\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 399ms/step - accuracy: 0.7591 - loss: 1.0526 - top5_acc: 0.9431"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/tf_gpu_test/.venv/lib/python3.12/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (115600000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 508ms/step - accuracy: 0.7791 - loss: 0.9333 - top5_acc: 0.9368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 560ms/step\n",
            "\n",
            "Final test metrics:\n",
            "Accuracy:          77.91%\n",
            "Macro F1-Score:    76.64%\n",
            "Macro Precision:   78.38%\n",
            "Macro Recall:      78.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/tf_gpu_test/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Final model saved to final_model.keras\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'history1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Final model saved to final_model.keras\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m     10\u001b[39m plot_training_history(\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     [\u001b[43mhistory1\u001b[49m, history2, history3],\n\u001b[32m     12\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mStage 1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStage 2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStage 3\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTRAINING COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'history1' is not defined"
          ]
        }
      ],
      "source": [
        "# Final evaluation\n",
        "model = tf.keras.models.load_model('model_stage3_best.keras')\n",
        "test_results, detailed_metrics = evaluate_model(model, test_ds)\n",
        "\n",
        "# Save final model\n",
        "model.save('final_model.keras')\n",
        "print(f\"\\n Final model saved to final_model.keras\")\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(\n",
        "    [history1, history2, history3],\n",
        "    ['Stage 1', 'Stage 2', 'Stage 3']\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nFinal Test Accuracy: {test_results[1]*100:.2f}%\")\n",
        "print(f\"Final Test Top-5 Accuracy: {test_results[2]*100:.2f}%\")\n",
        "print(f\"Macro F1-Score: {detailed_metrics['f1']*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43dfd4a9",
      "metadata": {},
      "source": [
        "## Error Analysis\n",
        "\n",
        "To better understand the behavior of the ConvNeXt-Small model, an error analysis was\n",
        "performed on the test set. This analysis focuses on identifying the most frequent\n",
        "misclassifications and understanding which species families are most commonly confused.\n",
        "\n",
        "A confusion matrix is computed and visualized in a row-normalized form to account for\n",
        "class imbalance. In addition, a detailed classification report is generated, including\n",
        "precision, recall, and F1-score for each class. Finally, the most frequent confusion\n",
        "pairs (true label → predicted label) are identified to highlight systematic errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0167dee",
      "metadata": {},
      "outputs": [],
      "source": [
        "def error_analysis(model, test_ds_eval, class_indices, normalize=True, top_k=15, save_prefix=\"test\"):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ERROR ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    test_ds_eval.reset()\n",
        "    y_pred_proba = model.predict(test_ds_eval, verbose=1)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "    y_true = test_ds_eval.classes\n",
        "\n",
        "    idx_to_class = {v: k for k, v in class_indices.items()}\n",
        "    class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "\n",
        "    if normalize:\n",
        "        cm_plot = cm.astype(\"float\") / np.maximum(cm.sum(axis=1, keepdims=True), 1)\n",
        "        title = \"Confusion Matrix (row-normalized)\"\n",
        "    else:\n",
        "        cm_plot = cm\n",
        "        title = \"Confusion Matrix (counts)\"\n",
        "\n",
        "    # Plot \n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(cm_plot)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.colorbar()\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_prefix}_confusion_matrix.png\", dpi=200)\n",
        "    plt.show()\n",
        "\n",
        "    # Report\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=class_names,\n",
        "        digits=4,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Top confused pairs\n",
        "    cm_off = cm.copy()\n",
        "    np.fill_diagonal(cm_off, 0)\n",
        "    pairs = []\n",
        "    for i in range(cm_off.shape[0]):\n",
        "        for j in range(cm_off.shape[1]):\n",
        "            if cm_off[i, j] > 0:\n",
        "                pairs.append((cm_off[i, j], class_names[i], class_names[j]))\n",
        "    pairs.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    print(f\"\\nTop {top_k} confusions (True -> Pred, count):\")\n",
        "    for cnt, t, p in pairs[:top_k]:\n",
        "        print(f\"  {t} -> {p}: {cnt}\")\n",
        "\n",
        "    return cm\n",
        "\n",
        "\n",
        "cm = error_analysis(\n",
        "    model,\n",
        "    test_ds_eval,\n",
        "    class_indices=test_ds_eval.class_indices,\n",
        "    normalize=True,\n",
        "    top_k=15,\n",
        "    save_prefix=\"test\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbeecc8",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "The ConvNeXt-Small model combined with a staged fine-tuning strategy achieves strong\n",
        "performance on the rare species classification task. The use of transfer learning,\n",
        "data augmentation, and class weighting allows the model to generalize well despite\n",
        "class imbalance and limited samples for rare families."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
