{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DD2XbwqhCzp"
      },
      "source": [
        "## **Custom CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWkCZkeIhDui"
      },
      "source": [
        "This notebook documents the creation and training of the custom Convolutional Neural Network (CNN). This serves as the baseline model against which the performance of the transfer learning models will be compared.\n",
        "\n",
        "Goal: Train a Custom CNN using 80/10/10 stratified split, 0-1 normalization, data augmentation, and class weights (due to class imbalance)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb4hZRw_iY26"
      },
      "source": [
        "## Project Setup and Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuRMFAJhikBQ"
      },
      "source": [
        "Imports and Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhLfvP6fh7sY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeBWpeBTMJTl",
        "outputId": "e3caba6a-7a5d-4ff2-fdfd-73f350c92ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.0.1 Requires-Python >=2.6,<=3.0; 0.0.2 Requires-Python >=2.6,<=3.0; 0.0.3 Requires-Python >=2.6,<=3.0; 0.0.4 Requires-Python >=2.6,<=3.0; 0.0.5 Requires-Python >=2.6,<=3.0; 0.0.6 Requires-Python >=2.6,<=3.0; 0.0.7 Requires-Python >=2.6,<=3.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement data_utils (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for data_utils\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install data_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54VzNtcwh-0T"
      },
      "outputs": [],
      "source": [
        "# Import utility functions from  uploaded files\n",
        "from data_utils import perform_stratified_split, DataGeneratorUtils, TARGET_SIZE, SEED\n",
        "from train_utils import compile_model, get_callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMIRUc-MMIeD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmF8G_xIjDgk",
        "outputId": "3190fef5-4ee8-457b-d268-ad6edbfb6075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ixH-8SqhCzs"
      },
      "outputs": [],
      "source": [
        "# Path to your metadata.csv file\n",
        "METADATA_PATH = \"/content/drive/MyDrive/Deep_Learning/rare_species/metadata.csv\"\n",
        "# Root directory containing all your original, un-split image files\n",
        "IMAGE_ROOT_DIR = \"/content/drive/MyDrive/Deep_Learning/rare_species\"\n",
        "# The target folder where the stratified data structure (train/val/test) will be created\n",
        "DATA_TARGET_DIR = \"/content/drive/MyDrive/Deep_Learning/data\"\n",
        "\n",
        "# Create the results directory if it doesn't exist to save model weights\n",
        "os.makedirs(\"/content/drive/MyDrive/Deep_Learning/outputs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLCWiewJimxC"
      },
      "source": [
        "Data Splitting and Generator Creation\n",
        "\n",
        "*We use the functions from data_utils.py to handle the reproducible split and the data pipeline creation.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W6HW4tBi1rZ"
      },
      "outputs": [],
      "source": [
        "# Load the metadata file\n",
        "try:\n",
        "    metadata_df = pd.read_csv(METADATA_PATH)\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: Metadata file not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DUjltjXjotW",
        "outputId": "ee563f4d-5c68-4fee-a86f-427a2db60c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Split: Train=9585, Validation=1199, Test=1199\n",
            "Organizing train set...\n",
            "Organizing validation set...\n",
            "Organizing test set...\n",
            "Data directory structure successfully created/updated.\n",
            "Data structure created/verified at: /content/drive/MyDrive/Deep_Learning/data\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN perform_stratified_split ONLY ONCE!\n",
        "data_base_path = perform_stratified_split(metadata_df, IMAGE_ROOT_DIR, DATA_TARGET_DIR)\n",
        "print(f\"Data structure created/verified at: {data_base_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYm2R3xKvpT-"
      },
      "outputs": [],
      "source": [
        "#!ls -R /content/drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDIbQuvhvh5P"
      },
      "source": [
        "note: there is a typo in the path file - rive instead of drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWLDX8dIwXv-"
      },
      "source": [
        "Verification: counting images per class in split directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuGGvraUwhEI"
      },
      "outputs": [],
      "source": [
        "def count_images_per_class(base_directory, set_name):\n",
        "    \"\"\"Counts the number of images in each class (family folder) for a given set.\"\"\"\n",
        "    directory = os.path.join(base_directory, set_name)\n",
        "    class_counts = {}\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        return {f\"ERROR: Directory not found at {directory}\": 0}\n",
        "\n",
        "    for folder in os.listdir(directory):\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Count files in the class folder\n",
        "            image_count = len([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            class_counts[folder] = image_count\n",
        "    return class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtb37uqGvyp2",
        "outputId": "5266fb8a-21b8-44ed-9bcd-14fd34204f10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Class Counts Verification ---\n",
            "Number of images per class in the TRAIN directory (Top 5):\n",
            "cercopithecidae    240\n",
            "dactyloidae        240\n",
            "formicidae         233\n",
            "plethodontidae     216\n",
            "carcharhinidae     216\n",
            "dtype: int64\n",
            "\n",
            "Number of images per class in the VALIDATION directory (Top 5):\n",
            "cercopithecidae    30\n",
            "dactyloidae        30\n",
            "formicidae         29\n",
            "plethodontidae     27\n",
            "carcharhinidae     27\n",
            "dtype: int64\n",
            "\n",
            "Number of images per class in the TEST directory (Top 5):\n",
            "dactyloidae        30\n",
            "cercopithecidae    30\n",
            "formicidae         29\n",
            "plethodontidae     27\n",
            "salamandridae      27\n",
            "dtype: int64\n",
            "\n",
            "Total images successfully counted across all splits: 11983\n"
          ]
        }
      ],
      "source": [
        "# Count images in train, validation, and test directories\n",
        "train_class_counts = count_images_per_class(DATA_TARGET_DIR, 'train')\n",
        "val_class_counts = count_images_per_class(DATA_TARGET_DIR, 'validation')\n",
        "test_class_counts = count_images_per_class(DATA_TARGET_DIR, 'test')\n",
        "\n",
        "# Display results\n",
        "print(\"\\n--- Class Counts Verification ---\")\n",
        "print(\"Number of images per class in the TRAIN directory (Top 5):\")\n",
        "# Sort and print for readability\n",
        "print(pd.Series(train_class_counts).sort_values(ascending=False).head(5))\n",
        "\n",
        "print(\"\\nNumber of images per class in the VALIDATION directory (Top 5):\")\n",
        "print(pd.Series(val_class_counts).sort_values(ascending=False).head(5))\n",
        "\n",
        "print(\"\\nNumber of images per class in the TEST directory (Top 5):\")\n",
        "print(pd.Series(test_class_counts).sort_values(ascending=False).head(5))\n",
        "\n",
        "# Check for overall size consistency\n",
        "total_counted = sum(train_class_counts.values()) + sum(val_class_counts.values()) + sum(test_class_counts.values())\n",
        "print(f\"\\nTotal images successfully counted across all splits: {total_counted}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZbMNijjyinZ"
      },
      "outputs": [],
      "source": [
        "data_base_path = DATA_TARGET_DIR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDivEMsJiUeo",
        "outputId": "287a053b-2166-4824-d707-35ca7105404c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9585 images belonging to 202 classes.\n",
            "Found 1199 images belonging to 202 classes.\n"
          ]
        }
      ],
      "source": [
        "#  Initialize Data Generators\n",
        "data_util = DataGeneratorUtils(data_base_path)\n",
        "\n",
        "train_generator = data_util.create_generators('train')\n",
        "val_generator = data_util.create_generators('validation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlNpZvTDysq9"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = train_generator.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8349i6nyoyj",
        "outputId": "70a47389-f0cb-431e-ebf7-02f10a5c0e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights calculated for 202 classes.\n",
            "\n",
            "Setup complete. Total classes: 202\n",
            "Train samples: 9585, Validation samples: 1199\n"
          ]
        }
      ],
      "source": [
        "# Calculate Class Weights (Crucial for rare species imbalance)\n",
        "class_weights = data_util.calculate_class_weights(train_generator)\n",
        "\n",
        "print(f\"\\nSetup complete. Total classes: {NUM_CLASSES}\")\n",
        "print(f\"Train samples: {train_generator.samples}, Validation samples: {val_generator.samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsvbjAUTZo-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f6bede-2315-4a02-abd5-fa141b589b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Data folder not found (Runtime restarted). Re-generating split...\n",
            "Data Split: Train=9585, Validation=1199, Test=1199\n",
            "Organizing train set...\n",
            "Organizing validation set...\n",
            "Organizing test set...\n",
            "Data directory structure successfully created/updated.\n",
            "âœ… Data successfully restored to local environment.\n"
          ]
        }
      ],
      "source": [
        "# --- INSERT THIS AT THE START OF YOUR CELL ---\n",
        "import os\n",
        "import pandas as pd\n",
        "from data_utils import perform_stratified_split\n",
        "\n",
        "# 1. Check if data exists. If not, recreate it.\n",
        "DATA_DIR = 'data'\n",
        "if not os.path.exists(os.path.join(DATA_DIR, 'train')):\n",
        "    print(f\"âš ï¸ Data folder not found (Runtime restarted). Re-generating split...\")\n",
        "\n",
        "    # Define Source Paths (Drive)\n",
        "    METADATA_PATH = \"/content/drive/MyDrive/Deep_Learning/rare_species/metadata.csv\"\n",
        "    IMAGE_ROOT = \"/content/drive/MyDrive/Deep_Learning/rare_species/\"\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(METADATA_PATH)\n",
        "        # This copies files from Drive -> Local Colab (Takes ~10-20 mins)\n",
        "        perform_stratified_split(df, IMAGE_ROOT, data_target_dir=DATA_DIR)\n",
        "        print(\"âœ… Data successfully restored to local environment.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error restoring data: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"âœ… Data folder found. Skipping split.\")\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmIzZKJTYmd-",
        "outputId": "bd8de955-a637-4de6-dcea-6ca2d870e8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Fixed Generators from: data\n",
            "Found 9585 images belonging to 202 classes.\n",
            "Found 1199 images belonging to 202 classes.\n",
            "\n",
            "ğŸ”¥ STARTING PHASE 1: Head Training (Frozen)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1496 - loss: 4.7627"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (115600000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 2.51617, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 1s/step - accuracy: 0.1499 - loss: 4.7601 - val_accuracy: 0.5296 - val_loss: 2.5162 - learning_rate: 0.0010\n",
            "Epoch 2/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4513 - loss: 2.7027\n",
            "Epoch 2: val_loss improved from 2.51617 to 2.31497, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 1s/step - accuracy: 0.4513 - loss: 2.7027 - val_accuracy: 0.5788 - val_loss: 2.3150 - learning_rate: 0.0010\n",
            "Epoch 3/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5308 - loss: 2.3688\n",
            "Epoch 3: val_loss improved from 2.31497 to 2.20218, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 1s/step - accuracy: 0.5308 - loss: 2.3689 - val_accuracy: 0.6314 - val_loss: 2.2022 - learning_rate: 0.0010\n",
            "Epoch 4/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5723 - loss: 2.1989\n",
            "Epoch 4: val_loss did not improve from 2.20218\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 1s/step - accuracy: 0.5722 - loss: 2.1991 - val_accuracy: 0.6289 - val_loss: 2.2060 - learning_rate: 0.0010\n",
            "Epoch 5/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5872 - loss: 2.1272\n",
            "Epoch 5: val_loss improved from 2.20218 to 2.15995, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.5872 - loss: 2.1272 - val_accuracy: 0.6447 - val_loss: 2.1600 - learning_rate: 0.0010\n",
            "Epoch 6/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6250 - loss: 2.0108\n",
            "Epoch 6: val_loss improved from 2.15995 to 2.12288, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 1s/step - accuracy: 0.6250 - loss: 2.0109 - val_accuracy: 0.6580 - val_loss: 2.1229 - learning_rate: 0.0010\n",
            "Epoch 7/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6413 - loss: 1.9683\n",
            "Epoch 7: val_loss improved from 2.12288 to 2.12019, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 1s/step - accuracy: 0.6412 - loss: 1.9684 - val_accuracy: 0.6489 - val_loss: 2.1202 - learning_rate: 0.0010\n",
            "Epoch 8/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6583 - loss: 1.8817\n",
            "Epoch 8: val_loss did not improve from 2.12019\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 1s/step - accuracy: 0.6583 - loss: 1.8818 - val_accuracy: 0.6522 - val_loss: 2.1225 - learning_rate: 0.0010\n",
            "Epoch 9/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6681 - loss: 1.8457\n",
            "Epoch 9: val_loss improved from 2.12019 to 2.09080, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 1s/step - accuracy: 0.6681 - loss: 1.8458 - val_accuracy: 0.6606 - val_loss: 2.0908 - learning_rate: 0.0010\n",
            "Epoch 10/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6786 - loss: 1.7854\n",
            "Epoch 10: val_loss improved from 2.09080 to 2.08158, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.6785 - loss: 1.7856 - val_accuracy: 0.6539 - val_loss: 2.0816 - learning_rate: 0.0010\n",
            "Epoch 11/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6824 - loss: 1.8076\n",
            "Epoch 11: val_loss improved from 2.08158 to 2.03789, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 1s/step - accuracy: 0.6824 - loss: 1.8077 - val_accuracy: 0.6831 - val_loss: 2.0379 - learning_rate: 0.0010\n",
            "Epoch 12/12\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6990 - loss: 1.7341\n",
            "Epoch 12: val_loss improved from 2.03789 to 2.01925, saving model to results/best_effnet_phase1.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 1s/step - accuracy: 0.6990 - loss: 1.7343 - val_accuracy: 0.6922 - val_loss: 2.0192 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "âœ… Phase 1 Complete. Saved.\n",
            "\n",
            "ğŸ”¥ STARTING PHASE 2: Fine-Tuning (Unfrozen)...\n",
            "Number of layers in base model: 270\n",
            "Training layers starting from layer 200\n",
            "Epoch 1/20\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6627 - loss: 1.8951\n",
            "Epoch 1: val_loss improved from inf to 2.06160, saving model to results/best_effnet_phase2_finetune.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 1s/step - accuracy: 0.6627 - loss: 1.8950 - val_accuracy: 0.6639 - val_loss: 2.0616 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6745 - loss: 1.8637\n",
            "Epoch 2: val_loss improved from 2.06160 to 2.04953, saving model to results/best_effnet_phase2_finetune.weights.h5\n",
            "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 1s/step - accuracy: 0.6745 - loss: 1.8636 - val_accuracy: 0.6681 - val_loss: 2.0495 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m187/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2:11\u001b[0m 1s/step - accuracy: 0.6928 - loss: 1.7685"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "# Define paths (Adjust 'data' if you are pulling from Drive)\n",
        "DATA_DIR = 'data'\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    # Fallback to Drive if local data was wiped\n",
        "    DATA_DIR = \"/content/drive/MyDrive/Deep_Learning/organized_data_224\"\n",
        "\n",
        "DRIVE_SAVE_PATH = \"/content/drive/MyDrive/Deep_Learning/models/\"\n",
        "os.makedirs(DRIVE_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# --- 2. THE FIX: GENERATORS WITHOUT RESCALING ---\n",
        "# EfficientNetV2 expects pixels in [0, 255], NOT [0, 1]\n",
        "class DataGeneratorUtils_Fixed:\n",
        "    def __init__(self, data_root):\n",
        "        self.data_root = data_root\n",
        "\n",
        "    def _custom_preprocess(self, image):\n",
        "        if tf.shape(image)[-1] == 1:\n",
        "            image = tf.image.grayscale_to_rgb(image)\n",
        "        return image\n",
        "\n",
        "    def create_generators(self, set_type):\n",
        "        data_dir = os.path.join(self.data_root, set_type)\n",
        "        if set_type == 'train':\n",
        "            datagen = ImageDataGenerator(\n",
        "                preprocessing_function=self._custom_preprocess, # No rescale!\n",
        "                rotation_range=20,\n",
        "                width_shift_range=0.2,\n",
        "                height_shift_range=0.2,\n",
        "                shear_range=0.2,\n",
        "                zoom_range=0.2,\n",
        "                horizontal_flip=True,\n",
        "                fill_mode='nearest'\n",
        "            )\n",
        "        else:\n",
        "            datagen = ImageDataGenerator(\n",
        "                preprocessing_function=self._custom_preprocess # No rescale!\n",
        "            )\n",
        "\n",
        "        return datagen.flow_from_directory(\n",
        "            data_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='categorical',\n",
        "            shuffle=(set_type == 'train'),\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "print(f\"Loading Fixed Generators from: {DATA_DIR}\")\n",
        "utils = DataGeneratorUtils_Fixed(DATA_DIR)\n",
        "train_generator = utils.create_generators('train')\n",
        "val_generator = utils.create_generators('validation')\n",
        "\n",
        "# Calculate weights again to be safe\n",
        "from sklearn.utils import class_weight\n",
        "y_train = train_generator.classes\n",
        "class_weights_arr = class_weight.compute_class_weight(\n",
        "    class_weight='balanced', classes=np.unique(y_train), y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_arr))\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "# --- 3. MODEL DEFINITION ---\n",
        "def build_efficientnet_model(input_shape, num_classes):\n",
        "    base_model = EfficientNetV2B0(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "    base_model.trainable = False  # Start Frozen\n",
        "\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return base_model, model\n",
        "\n",
        "def get_callbacks(phase_name):\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    return [\n",
        "        ModelCheckpoint(\n",
        "            filepath=f'results/best_{phase_name}.weights.h5',\n",
        "            monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1\n",
        "        ),\n",
        "        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)\n",
        "    ]\n",
        "\n",
        "# Build Model\n",
        "base_model, model = build_efficientnet_model((224, 224, 3), num_classes)\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 1: TRAIN HEAD (FROZEN BASE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ”¥ STARTING PHASE 1: Head Training (Frozen)...\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_p1 = model.fit(\n",
        "    train_generator,\n",
        "    epochs=12,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=get_callbacks('effnet_phase1'),\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "# Save Phase 1\n",
        "model.save('efficientnet_phase1.keras')\n",
        "shutil.copy('efficientnet_phase1.keras', os.path.join(DRIVE_SAVE_PATH, 'efficientnet_phase1.keras'))\n",
        "print(\"âœ… Phase 1 Complete. Saved.\")\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 2: FINE-TUNING (UNFROZEN BASE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ”¥ STARTING PHASE 2: Fine-Tuning (Unfrozen)...\")\n",
        "\n",
        "# 1. Unfreeze the base\n",
        "base_model.trainable = True\n",
        "\n",
        "# 2. Keep the bottom layers frozen (Standard practice to preserve edge detection)\n",
        "# EfficientNetV2B0 has ~270 layers. Let's freeze the bottom 200.\n",
        "fine_tune_at = 200\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(f\"Number of layers in base model: {len(base_model.layers)}\")\n",
        "print(f\"Training layers starting from layer {fine_tune_at}\")\n",
        "\n",
        "# 3. Re-compile with LOW Learning Rate (Critical!)\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-5), # 100x smaller LR\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Train again\n",
        "history_p2 = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=get_callbacks('effnet_phase2_finetune'),\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "# --- FINAL SAVE ---\n",
        "final_name = 'efficientnet_final_finetuned.keras'\n",
        "model.save(final_name)\n",
        "shutil.copy(final_name, os.path.join(DRIVE_SAVE_PATH, final_name))\n",
        "print(f\"ğŸ‰ ALL DONE! Final model saved to: {os.path.join(DRIVE_SAVE_PATH, final_name)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh5U2QTH9UmP"
      },
      "source": [
        "# Hyperparameter Tuner and Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAouPImv9NKN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04Tflw4g9fwk"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = 'custom_cnn_hyperband'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMUz4GW09x9w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80UNg-Mn9ivN"
      },
      "outputs": [],
      "source": [
        "# Early Stopping: Stops training if val_loss doesn't improve for 5 epochs\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32wlCDr39oE_"
      },
      "outputs": [],
      "source": [
        "# Reduce LR on Plateau: Reduces LR if val_loss doesn't improve for 5 epochs\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poXLi0yu9qnc"
      },
      "outputs": [],
      "source": [
        "callbacks = [early_stopping, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA8yN5pi91aR"
      },
      "outputs": [],
      "source": [
        "#Instantiate the Hyperband Tuner\n",
        "tuner = kt.Hyperband(\n",
        "    hypermodel=build_hypermodel,\n",
        "    objective='val_accuracy', # Maximize validation accuracy\n",
        "    max_epochs=30,           # Max epochs for a full training run\n",
        "    factor=3,                # Halving factor for Hyperband\n",
        "    directory='/content/drive/MyDrive/NOVA_IMS/Deep_Learning_Project/outputs', # Path to save results\n",
        "    project_name=PROJECT_NAME,\n",
        "    overwrite=True           # Overwrite previous search results\n",
        ")\n",
        "\n",
        "print(\"Tuner search space summary:\")\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzpFTkqn96rU"
      },
      "outputs": [],
      "source": [
        "# Run the search using the training and validation generators and class weights\n",
        "tuner.search(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFmhAW-5-AVA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZKM-ZKGhCzt"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}