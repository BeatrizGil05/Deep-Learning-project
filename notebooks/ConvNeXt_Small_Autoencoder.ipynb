{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ccfe4782",
      "metadata": {},
      "source": [
        "# Rare Species Classification using ConvNeXt-Small\n",
        "\n",
        "This notebook presents the training pipeline for a rare species image classification task.\n",
        "The goal is to classify images into biological families using a deep convolutional neural\n",
        "network based on ConvNeXt-Small, pretrained on ImageNet."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c13dd55",
      "metadata": {},
      "source": [
        "## Imports and Reproducibility\n",
        "\n",
        "This section loads all required libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib), and deep learning (TensorFlow/Keras). We also set a global random seed to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e193775a",
      "metadata": {
        "id": "e193775a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ConvNeXtSmall\n",
        "from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e146c4fc",
      "metadata": {},
      "source": [
        "## Hardware Configuration\n",
        "\n",
        "GPU availability is checked and memory growth is enabled to avoid out-of-memory errors\n",
        "during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "99afab38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99afab38",
        "outputId": "0a93d968-fe05-4987-947d-a665a4e5b2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GPU CHECK\n",
            "================================================================================\n",
            "⚠ No GPU detected - training will be slow!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GPU CHECK\")\n",
        "print(\"=\"*80)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✓ {len(gpus)} GPU(s) available\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"  - {gpu}\")\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    print(\"⚠ No GPU detected - training will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a7bb7e",
      "metadata": {},
      "source": [
        "## Dataset Loading and Cleaning\n",
        "\n",
        "The dataset metadata is loaded from a CSV file and the full file paths are construtcted. We perform a validity check to remove any entries where the image file does not exist or the label is missing. Finally, we handle duplicates and stratify the data into Train (80%), Validation (10%), and Test (10%) sets to preserve class distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b30a5340",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b30a5340",
        "outputId": "b33c0cc2-b842-413b-ae02-958418e8d7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DATA PREPROCESSING\n",
            "================================================================================\n",
            "Missing images: 0\n",
            "Duplicate metadata rows:\n",
            "Empty DataFrame\n",
            "Columns: [rare_species_id, eol_content_id, eol_page_id, kingdom, phylum, family, file_path, full_path, exists]\n",
            "Index: []\n",
            "Duplicate file paths:\n",
            "Empty DataFrame\n",
            "Columns: [rare_species_id, eol_content_id, eol_page_id, kingdom, phylum, family, file_path, full_path, exists]\n",
            "Index: []\n",
            "202\n",
            "Train: 9585\n",
            "Val: 1199\n",
            "Test: 1199\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df = pd.read_csv(r\"C:\\Users\\inesb\\Downloads\\Deep-Learning-project\\metadata.csv\")\n",
        "data_root_path = r\"C:\\Users\\inesb\\Downloads\\rare_species\"\n",
        "df['full_path'] = df['file_path'].apply(lambda x: os.path.join(data_root_path, x))\n",
        "\n",
        "# Remove rows with missing file paths or family labels\n",
        "df = df.dropna(subset=['file_path', 'family']).reset_index(drop=True)\n",
        "\n",
        "# Check for missing files\n",
        "df['exists'] = df['full_path'].apply(os.path.exists)\n",
        "missing = df[df['exists'] == False]\n",
        "\n",
        "print(\"Missing images:\", len(missing))\n",
        "if len(missing) > 0:\n",
        "    print(missing[['file_path']].head())\n",
        "\n",
        "# Drop rows with missing images\n",
        "df = df[df['exists'] == True].reset_index(drop=True)\n",
        "\n",
        "# Duplicate rows in metadata\n",
        "duplicate_rows = df[df.duplicated()]\n",
        "print(\"Duplicate metadata rows:\")\n",
        "print(duplicate_rows)\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Duplicate image paths\n",
        "duplicate_paths = df[df.duplicated(subset='full_path')]\n",
        "print(\"Duplicate file paths:\")\n",
        "print(duplicate_paths)\n",
        "df = df.drop_duplicates(subset='full_path').reset_index(drop=True)\n",
        "\n",
        "# Encode each category in the target variable\n",
        "df['family_encoded'] = pd.factorize(df['family'])[0]\n",
        "unique_families = df['family'].unique()\n",
        "print(df['family'].nunique()) # 202\n",
        "\n",
        "# Stratified split: 80% train, 10% val, 10% test\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.10, stratify=df[\"family\"], random_state=SEED)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1111, stratify=train_val_df[\"family\"], random_state=SEED)\n",
        "print(f\"Train: {len(train_df)}\")\n",
        "print(f\"Val: {len(val_df)}\")\n",
        "print(f\"Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98f4346",
      "metadata": {},
      "source": [
        "## Image Preprocessing and Data Augmentation\n",
        "\n",
        "Images are resized to 224×224 pixels and preprocessed using the official ConvNeXt\n",
        "preprocessing function. Data augmentation is applied only to the training set to\n",
        "improve generalization.\n",
        "\n",
        "The validation and test sets are only preprocessed without augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3ca7f0d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ca7f0d0",
        "outputId": "2500fe7d-f8f0-4122-eb9e-14d04f3d821a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "BUILDING DATA GENERATORS\n",
            "================================================================================\n",
            "Found 9585 validated image filenames belonging to 202 classes.\n",
            "Found 1199 validated image filenames belonging to 202 classes.\n",
            "Found 1199 validated image filenames belonging to 202 classes.\n",
            "Train batches: 600\n",
            "Val batches: 75\n",
            "Test batches: 75\n",
            "Number of classes: 202\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BUILDING DATA GENERATORS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=convnext_preprocess,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.15,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=convnext_preprocess\n",
        ")\n",
        "\n",
        "train_ds = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_ds)}\")\n",
        "print(f\"Val batches: {len(val_ds)}\")\n",
        "print(f\"Test batches: {len(test_ds)}\")\n",
        "print(f\"Number of classes: {len(train_ds.class_indices)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6540d5bf",
      "metadata": {},
      "source": [
        "## Class Imbalance Handling\n",
        "\n",
        "The dataset is highly imbalanced across species families. To mitigate this issue,\n",
        "class weights are computed from the training labels and passed to the loss function\n",
        "during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e1679664",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1679664",
        "outputId": "1e591e15-c1f6-4142-e51e-b78970f416e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPUTING CLASS WEIGHTS\n",
            "================================================================================\n",
            "Class weights computed for 202 classes\n",
            "Weight range: 0.198 to 2.063\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPUTING CLASS WEIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "labels = train_ds.classes\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "class_weights = dict(enumerate(weights))\n",
        "print(f\"Class weights computed for {len(class_weights)} classes\")\n",
        "print(f\"Weight range: {min(weights):.3f} to {max(weights):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d70d49",
      "metadata": {},
      "source": [
        "## Building a Denoising Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4eb7f2c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9585 files.\n",
            "Found 1199 files.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_i = tf.keras.utils.image_dataset_from_directory(r\"C:\\Users\\inesb\\Downloads\\Deep_Learning\\data\\train\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=None,\n",
        "    shuffle=True)\n",
        "\n",
        "val_i = tf.keras.utils.image_dataset_from_directory(r\"C:\\Users\\inesb\\Downloads\\Deep_Learning\\data\\validation\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode=None,\n",
        "    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0542f358",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "paths = train_df[\"full_path\"].values\n",
        "\n",
        "train_i = tf.data.Dataset.from_tensor_slices(paths)\n",
        "\n",
        "paths_val = val_df[\"full_path\"].values\n",
        "\n",
        "val_i = tf.data.Dataset.from_tensor_slices(paths_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1eebc3de",
      "metadata": {},
      "outputs": [],
      "source": [
        "noise_factor = 0.2\n",
        "\n",
        "def normalize_and_add_noise(x):\n",
        "    x = tf.cast(x, tf.float32) / 255.0\n",
        "    noise = tf.random.normal(tf.shape(x)) * noise_factor\n",
        "    x_noisy = tf.clip_by_value(x + noise, 0.0, 1.0)\n",
        "    return x_noisy, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f40bcd78",
      "metadata": {},
      "outputs": [],
      "source": [
        "noisy_train_i = (train_i.map(normalize_and_add_noise))\n",
        "\n",
        "noisy_val_i = (val_i.map(normalize_and_add_noise))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f7a249d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "class Denoise(Model):\n",
        "  def __init__(self):\n",
        "    super(Denoise, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(28, 28, 3)),\n",
        "      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Denoise()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ae62c1bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "ename": "UnimplementedError",
          "evalue": "{{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to float is not supported\n\t [[{{node Cast}}]] [Op:MakeIterator] name: ",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnimplementedError\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m autoencoder.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=losses.MeanSquaredError())\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_train_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_val_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inesb\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inesb\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6027\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6025\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6026\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6027\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mUnimplementedError\u001b[39m: {{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to float is not supported\n\t [[{{node Cast}}]] [Op:MakeIterator] name: "
          ]
        }
      ],
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "autoencoder.fit(noisy_train_i, validation_data = noisy_val_i, epochs = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bba40a81",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"denoise\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"denoise\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,608</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,897</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │         \u001b[38;5;34m1,608\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │         \u001b[38;5;34m1,897\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,517</span> (41.09 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,517\u001b[0m (41.09 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,505</span> (13.69 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,505\u001b[0m (13.69 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,012</span> (27.39 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,012\u001b[0m (27.39 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "autoencoder.summary()\n",
        "autoencoder.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5cb08e",
      "metadata": {},
      "source": [
        "## Model Architecture: ConvNeXt-Small\n",
        "\n",
        "ConvNeXt-Small pretrained on ImageNet is used as the backbone feature extractor.\n",
        "The original classification head is removed and replaced with a custom head consisting of:\n",
        "\n",
        "- Global Average Pooling\n",
        "- Fully connected layer with ReLU activation\n",
        "- Batch Normalization\n",
        "- Dropout for regularization\n",
        "- Final Softmax layer for family classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5f4cce94",
      "metadata": {
        "id": "5f4cce94"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes, trainable_backbone=False):\n",
        "    \"\"\"\n",
        "    Create ConvNeXt-Small model with custom head\n",
        "\n",
        "    Args:\n",
        "        num_classes: Number of output classes\n",
        "        trainable_backbone: Whether to make backbone trainable\n",
        "    \"\"\"\n",
        "    print(f\"\\nBuilding model (backbone trainable: {trainable_backbone})\")\n",
        "\n",
        "    # Load pretrained ConvNeXt-Small\n",
        "    base_model = ConvNeXtSmall(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "        pooling=None\n",
        "    )\n",
        "\n",
        "    base_model.trainable = trainable_backbone\n",
        "\n",
        "    # Build custom head\n",
        "    inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = autoencoder(inputs)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    print(f\"Total parameters: {model.count_params():,}\")\n",
        "    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def unfreeze_top_layers(model, percentage=0.3):\n",
        "    \"\"\"\n",
        "    Unfreeze top percentage of backbone layers\n",
        "\n",
        "    Args:\n",
        "        model: Keras model\n",
        "        percentage: Percentage of layers to unfreeze (from the end)\n",
        "    \"\"\"\n",
        "    base_model = model.layers[1]  # The ConvNeXt backbone\n",
        "    total_layers = len(base_model.layers)\n",
        "    unfreeze_from = int(total_layers * (1 - percentage))\n",
        "\n",
        "    print(f\"\\nUnfreezing top {percentage*100}% of backbone layers\")\n",
        "    print(f\"Total backbone layers: {total_layers}\")\n",
        "    print(f\"Unfreezing from layer {unfreeze_from} onwards\")\n",
        "\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:unfreeze_from]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "    print(f\"Trainable parameters after unfreezing: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dee0b78f",
      "metadata": {
        "id": "dee0b78f"
      },
      "outputs": [],
      "source": [
        "def get_callbacks(stage_name, patience=4):\n",
        "    \"\"\"Get training callbacks for a specific stage\"\"\"\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    callbacks = [\n",
        "        # Save best model\n",
        "        ModelCheckpoint(\n",
        "            filepath=f'model_{stage_name}_best.keras',\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "\n",
        "        # Reduce learning rate when stuck\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_accuracy',\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1,\n",
        "            mode='max'\n",
        "        ),\n",
        "\n",
        "        # Early stopping\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=patience,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1,\n",
        "            mode='max'\n",
        "        ),\n",
        "\n",
        "        # TensorBoard logging\n",
        "        TensorBoard(\n",
        "            log_dir=f'logs/{stage_name}_{timestamp}',\n",
        "            histogram_freq=0\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "HyOK9bzXYK03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "HyOK9bzXYK03",
        "outputId": "22fa2372-7bf1-42fc-af1e-695fdce62029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL ARCHITECTURE\n",
            "================================================================================\n",
            "\n",
            "Building model (backbone trainable: False)\n",
            "Total parameters: 49,954,090\n",
            "Trainable parameters: 498,378\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ convnext_small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">49,454,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ convnext_small (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │    \u001b[38;5;34m49,454,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m393,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m202\u001b[0m)            │       \u001b[38;5;34m103,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,954,090</span> (190.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,954,090\u001b[0m (190.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">498,378</span> (1.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m498,378\u001b[0m (1.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,455,712</span> (188.66 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m49,455,712\u001b[0m (188.66 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "    # Build model\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MODEL ARCHITECTURE\")\n",
        "    print(\"=\"*80)\n",
        "    num_classes = len(train_ds.class_indices)\n",
        "    model = build_model(num_classes=num_classes, trainable_backbone=False)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad747a07",
      "metadata": {},
      "source": [
        "## Training Strategy\n",
        "\n",
        "Training is performed in three stages:\n",
        "\n",
        "1. Training only the custom classification head with the backbone frozen\n",
        "2. Fine-tuning the top 30% of the ConvNeXt backbone\n",
        "3. Full fine-tuning of the backbone with Batch Normalization layers frozen\n",
        "\n",
        "This gradual unfreezing strategy stabilizes training and improves performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e46ea9",
      "metadata": {},
      "source": [
        "## Stage 1: Training with Frozen Backbone\n",
        "\n",
        "In the first stage, the ConvNeXt-Small backbone is kept frozen and only the newly\n",
        "added classification head is trained. This allows the model to adapt high-level\n",
        "features to the new task without destroying pretrained representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a20f6c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20f6c2f",
        "outputId": "36cbb3ee-3a7c-4e57-f247-804eebb2d0fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STAGE 1: Training with FROZEN backbone\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\inesb\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m 79/600\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25:15\u001b[0m 3s/step - accuracy: 0.0076 - loss: 5.6656 - top5_acc: 0.0306"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STAGE 1: Training with FROZEN backbone\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=3e-4,\n",
        "        weight_decay=1e-4\n",
        "    ),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')]\n",
        ")\n",
        "\n",
        "# Train\n",
        "history1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=8,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=get_callbacks('stage1', patience=4),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save\n",
        "model.save('model_after_stage1.keras')\n",
        "print(f\"\\nStage 1 COMPLETE! Model saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8bdeca6",
      "metadata": {},
      "source": [
        "## Stage 2: Partial Fine-Tuning (Top 30%)\n",
        "\n",
        "In the second stage, the top 30% of ConvNeXt-Small layers are unfrozen.\n",
        "A lower learning rate is used to refine pretrained features while\n",
        "reducing the risk of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "XtWPVPkYUz-P",
      "metadata": {
        "id": "XtWPVPkYUz-P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STAGE 2: Training with PARTIAL backbone unfreezing (top 30%)\n",
            "================================================================================\n",
            "WARNING:tensorflow:From c:\\Users\\inesb\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'unfreeze_top_layers' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m model = tf.keras.models.load_model(\u001b[33m'\u001b[39m\u001b[33mmodel_after_stage1.keras\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m#balazs: switched it with next line\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Unfreeze top layers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43munfreeze_top_layers\u001b[49m(model, percentage=\u001b[32m0.3\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Compile with lower learning rate\u001b[39;00m\n\u001b[32m     12\u001b[39m model.compile(\n\u001b[32m     13\u001b[39m     optimizer=tf.keras.optimizers.AdamW(\n\u001b[32m     14\u001b[39m         learning_rate=\u001b[32m1e-4\u001b[39m,\u001b[38;5;66;03m# balazs: it was too low didnt learn. was 1e-5\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, tf.keras.metrics.TopKCategoricalAccuracy(k=\u001b[32m5\u001b[39m, name=\u001b[33m'\u001b[39m\u001b[33mtop5_acc\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m     19\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'unfreeze_top_layers' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STAGE 2: Training with PARTIAL backbone unfreezing (top 30%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = tf.keras.models.load_model('model_after_stage1.keras') #balazs: switched it with next line\n",
        "\n",
        "# Unfreeze top layers\n",
        "unfreeze_top_layers(model, percentage=0.3)\n",
        "\n",
        "\n",
        "# Compile with lower learning rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(\n",
        "        learning_rate=1e-4,# balazs: it was too low didnt learn. was 1e-5\n",
        "        weight_decay=1e-4\n",
        "    ),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')]\n",
        ")\n",
        "\n",
        "# Train\n",
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=15,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=get_callbacks('stage2', patience=5),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save\n",
        "model.save('model_after_stage2.keras')\n",
        "print(f\"\\nStage 2 COMPLETE! Model saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3720999",
      "metadata": {},
      "source": [
        "## Stage 3: Full Fine-Tuning\n",
        "\n",
        "In the final stage, all backbone layers are unfrozen except Batch Normalization layers,\n",
        "which remain frozen for training stability. Mixed-precision training and a smaller\n",
        "batch size are used to fit GPU memory constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "KsXwRQdXU0Lh",
      "metadata": {
        "id": "KsXwRQdXU0Lh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "STAGE 3: Training with FULL backbone unfreezing\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "File not found: filepath=model_after_stage2.keras. Please ensure the file is an accessible `.keras` zip file.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSTAGE 3: Training with FULL backbone unfreezing\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_after_stage2.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# --- Mixed precision ---\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mixed_precision\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inesb\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: File not found: filepath=model_after_stage2.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "source": [
        "# Stage 3: Fine-tune all layers0\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STAGE 3: Training with FULL backbone unfreezing\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = tf.keras.models.load_model('model_after_stage2.keras')\n",
        "\n",
        "# --- Mixed precision ---\n",
        "from tensorflow.keras import mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# --- Recreate generators with smaller batch size if needed ---\n",
        "NEW_BATCH_SIZE = 4\n",
        "\n",
        "train_ds_stage3 = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=NEW_BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds_stage3 = val_test_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='full_path',\n",
        "    y_col='family',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=NEW_BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\"\"\"\n",
        "# Unfreeze all layers\n",
        "base_model = model.layers[1]\n",
        "base_model.trainable = True\"\"\"\n",
        "\n",
        "# Unfreeze all layers but freeze BatchNorm layers\n",
        "base_model = model.layers[1]\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n",
        "\n",
        "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Compile with even lower learning rate\n",
        "opt = tf.keras.optimizers.AdamW(\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=1e-5\n",
        ")\n",
        "opt = mixed_precision.LossScaleOptimizer(opt)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_acc')]\n",
        ")\n",
        "\n",
        "# Train\n",
        "history3 = model.fit(\n",
        "    train_ds_stage3,\n",
        "    validation_data=val_ds_stage3,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=get_callbacks('stage3', patience=5),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save\n",
        "model.save('model_after_stage3.keras')\n",
        "print(f\"\\nStage 3 COMPLETE! Model saved.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be1f2bdc",
      "metadata": {},
      "source": [
        "## Final Evaluation\n",
        "\n",
        "The final model is evaluated on the independent test set using accuracy\n",
        "and macro-averaged precision, recall, and F1-score.\n",
        "Macro metrics are reported to account for class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7077b6a3",
      "metadata": {
        "id": "7077b6a3"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_ds):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL EVALUATION ON TEST SET\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results = model.evaluate(test_ds, verbose=1)\n",
        "    test_ds.reset()\n",
        "    predictions = model.predict(test_ds, verbose=1)\n",
        "\n",
        "    # Convert probabilities to class labels\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    y_true = test_ds.classes\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    prec_macro = precision_score(y_true, y_pred, average='macro')\n",
        "    rec_macro = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(\"\\nFinal test metrics:\")\n",
        "    print(f\"Accuracy:          {acc:.2%}\")\n",
        "    print(f\"Macro F1-Score:    {f1_macro:.2%}\")\n",
        "    print(f\"Macro Precision:   {prec_macro:.2%}\")\n",
        "    print(f\"Macro Recall:      {rec_macro:.2%}\")\n",
        "\n",
        "    return results, {'accuracy': acc, 'f1': f1_macro, 'precision': prec_macro, 'recall': rec_macro}\n",
        "\n",
        "def plot_training_history(histories, stage_names):\n",
        "    \"\"\"Plot training curves for all stages with phase separation lines\"\"\"\n",
        "\n",
        "    # Combine all histories\n",
        "    acc = []\n",
        "    val_acc = []\n",
        "    loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for history in histories:\n",
        "        if history is not None:\n",
        "            acc.extend(history.history['accuracy'])\n",
        "            val_acc.extend(history.history['val_accuracy'])\n",
        "            loss.extend(history.history['loss'])\n",
        "            val_loss.extend(history.history['val_loss'])\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "\n",
        "    # Add vertical lines to show where each phase started\n",
        "    phase1_end = len(histories[0].history['accuracy'])\n",
        "    phase2_end = phase1_end + len(histories[1].history['accuracy'])\n",
        "\n",
        "    plt.axvline(x=phase1_end, color='black', linestyle='--', label='Start Stage 2', linewidth=2)\n",
        "    plt.axvline(x=phase2_end, color='red', linestyle='--', label='Start Stage 3', linewidth=2)\n",
        "\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "\n",
        "    plt.axvline(x=phase1_end, color='black', linestyle='--', label='Start Stage 2', linewidth=2)\n",
        "    plt.axvline(x=phase2_end, color='red', linestyle='--', label='Start Stage 3', linewidth=2)\n",
        "\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=300)\n",
        "    print(f\"\\n Training history plot saved to training_history.png\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "59d94c40",
      "metadata": {
        "id": "59d94c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL EVALUATION ON TEST SET\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-11 01:04:58.071142: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:58.302014: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:59.070452: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 96 bytes spill stores, 96 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:59.259784: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 64 bytes spill stores, 64 bytes spill loads\n",
            "\n",
            "2025-12-11 01:04:59.277006: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "2025-12-11 01:05:00.430774: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 360 bytes spill stores, 360 bytes spill loads\n",
            "\n",
            "2025-12-11 01:05:00.464510: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_12', 664 bytes spill stores, 664 bytes spill loads\n",
            "\n",
            "2025-12-11 01:05:04.713891: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:05.784804: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:06.460915: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:06.790639: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.064524: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.110137: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng3{k11=0} for conv (f32[16,768,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,768,7,7]{3,2,1,0}, f32[768,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=768, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
            "2025-12-11 01:05:07.344499: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.642443: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:07.962583: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:08.295056: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:08.617001: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:08.941385: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:09.246463: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-12-11 01:05:09.254836: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.144878511s\n",
            "Trying algorithm eng3{k11=0} for conv (f32[16,768,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,768,7,7]{3,2,1,0}, f32[768,1,7,7]{3,2,1,0}), window={size=7x7 pad=3_3x3_3}, dim_labels=bf01_oi01->bf01, feature_group_count=768, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m21/75\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 399ms/step - accuracy: 0.7591 - loss: 1.0526 - top5_acc: 0.9431"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/tf_gpu_test/.venv/lib/python3.12/site-packages/PIL/Image.py:3432: DecompressionBombWarning: Image size (115600000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 508ms/step - accuracy: 0.7791 - loss: 0.9333 - top5_acc: 0.9368\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 560ms/step\n",
            "\n",
            "Final test metrics:\n",
            "Accuracy:          77.91%\n",
            "Macro F1-Score:    76.64%\n",
            "Macro Precision:   78.38%\n",
            "Macro Recall:      78.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/tf_gpu_test/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Final model saved to final_model.keras\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'history1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Final model saved to final_model.keras\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m     10\u001b[39m plot_training_history(\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     [\u001b[43mhistory1\u001b[49m, history2, history3],\n\u001b[32m     12\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mStage 1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStage 2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStage 3\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTRAINING COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'history1' is not defined"
          ]
        }
      ],
      "source": [
        "# Final evaluation\n",
        "model = tf.keras.models.load_model('model_stage3_best.keras')\n",
        "test_results, detailed_metrics = evaluate_model(model, test_ds)\n",
        "\n",
        "# Save final model\n",
        "model.save('final_model.keras')\n",
        "print(f\"\\n Final model saved to final_model.keras\")\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(\n",
        "    [history1, history2, history3],\n",
        "    ['Stage 1', 'Stage 2', 'Stage 3']\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nFinal Test Accuracy: {test_results[1]*100:.2f}%\")\n",
        "print(f\"Final Test Top-5 Accuracy: {test_results[2]*100:.2f}%\")\n",
        "print(f\"Macro F1-Score: {detailed_metrics['f1']*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43dfd4a9",
      "metadata": {},
      "source": [
        "## Error Analysis\n",
        "\n",
        "To better understand the behavior of the ConvNeXt-Small model, an error analysis was\n",
        "performed on the test set. This analysis focuses on identifying the most frequent\n",
        "misclassifications and understanding which species families are most commonly confused.\n",
        "\n",
        "A confusion matrix is computed and visualized in a row-normalized form to account for\n",
        "class imbalance. In addition, a detailed classification report is generated, including\n",
        "precision, recall, and F1-score for each class. Finally, the most frequent confusion\n",
        "pairs (true label → predicted label) are identified to highlight systematic errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0167dee",
      "metadata": {},
      "outputs": [],
      "source": [
        "def error_analysis(model, test_ds_eval, class_indices, normalize=True, top_k=15, save_prefix=\"test\"):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ERROR ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    test_ds_eval.reset()\n",
        "    y_pred_proba = model.predict(test_ds_eval, verbose=1)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "    y_true = test_ds_eval.classes\n",
        "\n",
        "    idx_to_class = {v: k for k, v in class_indices.items()}\n",
        "    class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "\n",
        "    if normalize:\n",
        "        cm_plot = cm.astype(\"float\") / np.maximum(cm.sum(axis=1, keepdims=True), 1)\n",
        "        title = \"Confusion Matrix (row-normalized)\"\n",
        "    else:\n",
        "        cm_plot = cm\n",
        "        title = \"Confusion Matrix (counts)\"\n",
        "\n",
        "    # Plot \n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.imshow(cm_plot)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.colorbar()\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_prefix}_confusion_matrix.png\", dpi=200)\n",
        "    plt.show()\n",
        "\n",
        "    # Report\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=class_names,\n",
        "        digits=4,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Top confused pairs\n",
        "    cm_off = cm.copy()\n",
        "    np.fill_diagonal(cm_off, 0)\n",
        "    pairs = []\n",
        "    for i in range(cm_off.shape[0]):\n",
        "        for j in range(cm_off.shape[1]):\n",
        "            if cm_off[i, j] > 0:\n",
        "                pairs.append((cm_off[i, j], class_names[i], class_names[j]))\n",
        "    pairs.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    print(f\"\\nTop {top_k} confusions (True -> Pred, count):\")\n",
        "    for cnt, t, p in pairs[:top_k]:\n",
        "        print(f\"  {t} -> {p}: {cnt}\")\n",
        "\n",
        "    return cm\n",
        "\n",
        "\n",
        "cm = error_analysis(\n",
        "    model,\n",
        "    test_ds_eval,\n",
        "    class_indices=test_ds_eval.class_indices,\n",
        "    normalize=True,\n",
        "    top_k=15,\n",
        "    save_prefix=\"test\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbeecc8",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "The ConvNeXt-Small model combined with a staged fine-tuning strategy achieves strong\n",
        "performance on the rare species classification task. The use of transfer learning,\n",
        "data augmentation, and class weighting allows the model to generalize well despite\n",
        "class imbalance and limited samples for rare families."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
